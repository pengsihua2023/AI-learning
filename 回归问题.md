## 回归问题
- 第一版代码 
```
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# 加载波士顿房价数据集
(X, y), (_, _) = tf.keras.datasets.boston_housing.load_data(test_split=0)

# 数据标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 构建改进的神经网络模型
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # 隐藏层
    layers.Dense(32, activation='relu'),  # 第二个隐藏层
    layers.Dense(1)  # 输出层
])

# 编译模型，使用更小的学习率
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

# 训练模型，增加 epoch 数并添加早停机制
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)

# 评估模型
loss, mae = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Loss: {loss:.4f}, Test MAE: {mae:.4f}")

# 预测
y_pred = model.predict(X_test[:5])
print("Predictions for first 5 test samples:", y_pred.flatten())
print("Actual values:", y_test[:5])

```
### 结果
11/11 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 5.4454 - mae: 1.7790 - val_loss: 7.5367 - val_mae: 1.9705  
Test Loss: 28.6256, Test MAE: 2.9774  
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step  
Predictions for first 5 test samples: [21.798922 21.89294  20.243843 33.85427  21.61176 ]  
Actual values: [18.2 21.4 21.5 36.4 20.2]  
- 第二版代码
```
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# 加载波士顿房价数据集
(X, y), (_, _) = tf.keras.datasets.boston_housing.load_data(test_split=0)

# 数据标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 构建优化模型
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],), 
                 kernel_regularizer=regularizers.l2(0.01)),  # L2正则化
    layers.Dropout(0.2),  # Dropout层
    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    layers.Dropout(0.2),
    layers.Dense(1)
])

# 编译模型
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

# 训练模型
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
model.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.2, 
          callbacks=[early_stopping], verbose=1)

# 评估模型
loss, mae = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Loss: {loss:.4f}, Test MAE: {mae:.4f}")

# 预测
y_pred = model.predict(X_test[:5])
print("Predictions for first 5 test samples:", y_pred.flatten())
print("Actual values:", y_test[:5])
```
### 训练结果
21/21 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 15.5459 - mae: 2.9512 - val_loss: 7.5879 - val_mae: 1.8665  
Test Loss: 28.6987, Test MAE: 3.1621  
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step  
Predictions for first 5 test samples: [19.722134 21.551369 19.76431  34.056454 22.540033]  
Actual values: [18.2 21.4 21.5 36.4 20.2]  
