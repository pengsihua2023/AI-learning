## U-Net (2015) 
提出者：Olaf Ronneberger 等  
特点：对称编码-解码结构，跳跃连接保留细节信息，专为图像分割设计。  
应用：医学图像分割、语义分割。  
掌握要点：编码-解码架构、特征融合。  
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/00b53895-4271-48df-abc5-f39e671ec419" />

## 代码
以下是对 `brats2020_unet.py` 代码实现的基本功能的详细描述。该代码基于 BraTS 2020 数据集，利用 PyTorch 框架实现了一个 U-Net 模型，用于脑肿瘤分割任务。以下是其核心功能的逐步解析：

### 1. **环境和随机种子设置**
- **功能**: 初始化 Python 环境，设置随机种子以确保实验结果的可重现性。
- **实现**:
  - 使用 `np.random.seed(SEED)`、`torch.manual_seed(SEED)` 设置 NumPy 和 PyTorch 的随机种子，`SEED = 42` 为固定值。
- **目的**: 保证每次运行模型训练时的随机初始化和数据shuffle一致，便于调试和比较结果。

### 2. **数据目录检查**
- **功能**: 验证数据集目录是否存在，若不存在则提示用户手动下载并放置数据。
- **实现**:
  - 定义 `data_dir = "F:/00-数据/Adam/brats2020"` 作为数据集路径。
  - 使用 `os.path.exists()` 检查目录，若不存在抛出异常并提供下载链接。
- **目的**: 确保代码运行前数据集已正确准备，减少运行时错误。

### 3. **U-Net 模型定义**
- **功能**: 实现一个经典的 U-Net 神经网络架构，用于图像分割。
- **实现**:
  - **输入通道 (`in_channels=4`)**: 支持 BraTS 2020 的四种模态（T1、T2、FLAIR、T1ce）。
  - **输出通道 (`out_channels=1`)**: 当前简化为二值分割（肿瘤/非肿瘤，可扩展为多类）。
  - **结构**:
    - **编码器**: 包含 3 层卷积块（`conv_block`），每层后接 `MaxPool2d` 下采样，特征数从 32 倍增至 256。
    - **瓶颈层**: 最高层特征（256），进行卷积处理。
    - **解码器**: 3 层上采样（`ConvTranspose2d`）与编码器特征通过跳跃连接 (`crop_and_concat`) 合并。
    - **最终层**: 1x1 卷积生成分割输出。
  - **激活函数**: 使用 ReLU，批归一化 (`BatchNorm2d`) 稳定训练。
- **目的**: 提取图像特征并生成分割掩码，适用于医学图像的精细分割。

### 4. **数据集加载 (Brats2020Dataset)**
- **功能**: 加载 BraTS 2020 数据集的 NIfTI 文件，处理为 2D 切片并准备训练数据。
- **实现**:
  - **文件组织**: 遍历 `data_dir` 下病例文件夹，收集 `t1.nii.gz`, `t2.nii.gz`, `flair.nii.gz`, `t1ce.nii.gz` 和 `seg.nii.gz` 文件。
  - **数据预处理**:
    - 加载 NIfTI 数据，堆叠四种模态为 `[4, H, W, D]`。
    - 提取中间切片 (`slice_idx = image.shape[2] // 2`)，转为 `[4, H, W]`。
    - 归一化 (`image / np.max(image)`)，掩码二值化 (`mask > 0`)。
    - 使用 `transforms` 调整大小为 512x512 并转为张量。
- **目的**: 提供批量化的训练数据，适配 U-Net 的输入格式。

### 5. **训练循环**
- **功能**: 执行模型训练，优化网络参数以最小化损失。
- **实现**:
  - **设备选择**: 使用 `torch.device("cuda" if torch.cuda.is_available() else "cpu")` 自动选择 GPU 或 CPU。
  - **优化器**: `Adam` 优化器，学习率 `0.001`。
  - **损失函数**: `BCEWithLogitsLoss` 适合二值分割。
  - **训练过程**:
    - 10 个 epoch，批大小 4。
    - 每 10 个 batch 打印平均损失。
    - 前向传播、反向传播 (`loss.backward()`) 和参数更新 (`optimizer.step()`)。
- **目的**: 训练模型识别脑肿瘤区域，逐步降低预测误差。

### 6. **可视化 (visualize_features)**
- **功能**: 每 epoch 结束后可视化输入图像、分割输出和中间特征图。
- **实现**:
  - 提取样本数据，转换为 NumPy 数组。
  - 归一化输入图像，显示 T1 模态。
  - 使用灰度图显示输入/输出，`viridis` 颜色图显示特征图 (6 个层：enc1, enc2, enc3, bottleneck, dec3, dec2)。
  - 2x4 子图布局，包含标题和关闭坐标轴。
- **目的**: 监控训练过程，直观评估模型性能。

### 7. **主函数 (Main)**
- **功能**: 整合上述模块，执行完整训练流程。
- **实现**:
  - 初始化数据集、模型、优化器和损失函数。
  - 运行训练循环，周期性可视化。
  - 训练完成后打印结束信息。
- **目的**: 提供端到端执行入口，简化用户操作。

### 总体功能总结
- **输入**: BraTS 2020 多模态 MRI 图像 (NIfTI 格式)。
- **输出**: 2D 脑肿瘤分割掩码 (二值或可扩展为多类)。
- **核心流程**: 数据加载 → 模型训练 → 结果可视化。
- **适用场景**: 医学图像分割，尤其是脑肿瘤检测和边界绘制。

### 注意事项
- **数据准备**: 需要手动下载并解压 BraTS 2020 数据到指定路径。
- **局限性**: 当前为 2D U-Net，多类分割和 3D 训练需进一步调整。
- **性能**: 训练依赖 GPU，数据量大时需优化内存使用。

```
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import nibabel as nib
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import os
from tqdm import tqdm

# Set random seeds for reproducibility
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)

# Define data directory (manually set after downloading BraTS 2020)
data_dir = "F:/00-数据/Adam/brats2020"  # Adjust this path to your downloaded data
if not os.path.exists(data_dir):
    raise Exception(f"Directory {data_dir} does not exist. Please download the BraTS 2020 dataset from https://www.med.upenn.edu/cbica/brats2020/data.html, extract it, and place it in {data_dir}.")

# U-Net Model
class UNet(nn.Module):
    def __init__(self, in_channels=4, out_channels=1, init_features=32):
        super(UNet, self).__init__()
        features = init_features
        self.enc1 = self.conv_block(in_channels, features)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.enc2 = self.conv_block(features, features * 2)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.enc3 = self.conv_block(features * 2, features * 4)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.bottleneck = self.conv_block(features * 4, features * 8)
        
        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(features * 8, features * 4)
        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(features * 4, features * 2)
        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(features * 2, features)
        
        self.conv_final = nn.Conv2d(features, out_channels, kernel_size=1)
        
    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        enc1 = self.enc1(x)
        enc2 = self.enc2(self.pool1(enc1))
        enc3 = self.enc3(self.pool2(enc2))
        
        bottleneck = self.bottleneck(self.pool3(enc3))
        
        dec3 = self.upconv3(bottleneck)
        dec3 = self.crop_and_concat(dec3, enc3)
        dec3 = self.dec3(dec3)
        
        dec2 = self.upconv2(dec3)
        dec2 = self.crop_and_concat(dec2, enc2)
        dec2 = self.dec2(dec2)
        
        dec1 = self.upconv1(dec2)
        dec1 = self.crop_and_concat(dec1, enc1)
        dec1 = self.dec1(dec1)
        
        return self.conv_final(dec1), enc1, enc2, enc3, bottleneck, dec3, dec2, dec1
    
    def crop_and_concat(self, upsampled, bypass):
        diff_y = bypass.size()[2] - upsampled.size()[2]
        diff_x = bypass.size()[3] - upsampled.size()[3]
        if diff_y != 0 or diff_x != 0:
            bypass = bypass[:, :, diff_y//2:-(diff_y//2), diff_x//2:-(diff_x//2)]
        return torch.cat((upsampled, bypass), dim=1)

# Dataset
class Brats2020Dataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.image_paths = []
        self.mask_paths = []
        
        modalities = ['t1', 't2', 'flair', 't1ce']
        for case in os.listdir(data_dir):
            case_path = os.path.join(data_dir, case)
            if os.path.isdir(case_path):
                seg_path = os.path.join(case_path, f"{case}_seg.nii.gz")
                if os.path.exists(seg_path):
                    image_paths = [os.path.join(case_path, f"{case}_{mod}.nii.gz") for mod in modalities]
                    if all(os.path.exists(p) for p in image_paths):
                        self.image_paths.append(image_paths)
                        self.mask_paths.append(seg_path)
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        images = [nib.load(path).get_fdata() for path in self.image_paths[idx]]
        image = np.stack(images, axis=0)  # [4, H, W, D]
        mask = nib.load(self.mask_paths[idx]).get_fdata()  # [H, W, D]
        
        # Take a 2D slice (e.g., middle slice)
        slice_idx = image.shape[2] // 2
        image = image[:, :, slice_idx, :]  # [4, H, W]
        mask = mask[:, :, slice_idx]  # [H, W]
        
        # Normalize image
        image = image.astype(np.float32) / np.max(image)
        mask = (mask > 0).astype(np.float32)  # Binary mask (simplified, can be multi-class)
        
        if self.transform:
            image = np.transpose(image, (1, 2, 0))  # [H, W, 4] to [H, W, C]
            image = self.transform(image)
            mask = self.transform(mask.unsqueeze(0)).squeeze(0)  # Add channel dim for transform
        
        return image, mask

# Visualization
def visualize_features(input_img, output, enc1, enc2, enc3, bottleneck, dec3, dec2, dec1):
    input_img = input_img.cpu().numpy().squeeze().transpose(1, 2, 0)
    output = output.cpu().numpy().squeeze()
    
    if input_img.max() > 1.0:
        input_img = input_img / input_img.max()
    
    enc1 = enc1.cpu().numpy().squeeze()[0]
    enc2 = enc2.cpu().numpy().squeeze()[0]
    enc3 = enc3.cpu().numpy().squeeze()[0]
    bottleneck = bottleneck.cpu().numpy().squeeze()[0]
    dec3 = dec3.cpu().numpy().squeeze()[0]
    dec2 = dec2.cpu().numpy().squeeze()[0]
    dec1 = dec1.cpu().numpy().squeeze()[0]
    
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes[0, 0].imshow(input_img[:, :, 0], cmap='gray')
    axes[0, 0].set_title("Input Image (T1)")
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(output, cmap='gray')
    axes[0, 1].set_title("Output Segmentation")
    axes[0, 1].axis('off')
    
    axes[0, 2].imshow(enc1, cmap='viridis')
    axes[0, 2].set_title("Encoder 1 (First Channel)")
    axes[0, 2].axis('off')
    
    axes[0, 3].imshow(enc2, cmap='viridis')
    axes[0, 3].set_title("Encoder 2 (First Channel)")
    axes[0, 3].axis('off')
    
    axes[1, 0].imshow(enc3, cmap='viridis')
    axes[1, 0].set_title("Encoder 3 (First Channel)")
    axes[1, 0].axis('off')
    
    axes[1, 1].imshow(bottleneck, cmap='viridis')
    axes[1, 1].set_title("Bottleneck (First Channel)")
    axes[1, 1].axis('off')
    
    axes[1, 2].imshow(dec3, cmap='viridis')
    axes[1, 2].set_title("Decoder 3 (First Channel)")
    axes[1, 2].axis('off')
    
    axes[1, 3].imshow(dec2, cmap='viridis')
    axes[1, 3].set_title("Decoder 2 (First Channel)")
    axes[1, 3].axis('off')
    
    plt.tight_layout()
    plt.show()

# Main
if __name__ == "__main__":
    # Data
    dataset_path = data_dir
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((512, 512), antialias=True)
    ])
    dataset = Brats2020Dataset(dataset_path, transform=transform)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)
    
    # Model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(in_channels=4, out_channels=1).to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # Training
    model.train()
    num_epochs = 10
    for epoch in range(num_epochs):
        running_loss = 0.0
        for batch_idx, (images, masks) in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}")):
            images, masks = images.to(device), masks.to(device)
            
            optimizer.zero_grad()
            outputs, enc1, enc2, enc3, bottleneck, dec3, dec2, dec1 = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            if batch_idx % 10 == 9:
                print(f"Batch {batch_idx+1}, Loss: {running_loss/10:.4f}")
                running_loss = 0.0
        
        # Visualize a sample
        with torch.no_grad():
            model.eval()
            sample_img, sample_mask = images[0].unsqueeze(0), masks[0].unsqueeze(0)
            output, enc1_v, enc2_v, enc3_v, bottleneck_v, dec3_v, dec2_v, dec1_v = model(sample_img)
            visualize_features(sample_img, output, enc1_v, enc2_v, enc3_v, bottleneck_v, dec3_v, dec2_v, dec1_v)
        model.train()
    
    print("Training finished!")

```
## 训练结果
数据还没有现在好。。。
