## 循环神经网络
循环神经网络（Recurrent Neural Network, RNN）  
- 重要性：RNN 适合处理序列数据（如文本、语音），是自然语言处理和时间序列预测的基础。
- 核心概念：
RNN 有“记忆”，可以记住之前的输入，适合处理有序数据（如句子）。  
变种如 LSTM（长短期记忆网络）能记住更长的序列。  
- 应用：语音识别（如 Siri）、机器翻译、股票预测。
- 为什么教：RNN 展示深度学习如何处理动态数据，与语音助手等应用相关。
<img width="1194" height="346" alt="image" src="https://github.com/user-attachments/assets/fb831947-92f9-4b61-86ec-6049d0e50843" />
RNN: 基本的循环神经网络单元，通过tanh激活函数处理输入Xt和前一时刻的隐藏状态h(t-1)，生成当前隐藏状态h(t)。它简单但容易遇到梯度消失问题，限制了长序列的处理能力。  
RNN（循环神经网络）被认为具有“记忆”是因为它通过隐藏状态h(t)在时间步之间传递信息。当前时刻的隐藏状态不仅依赖于当前输入x(t)，还依赖于前一时刻的隐藏状态h(t-1)，从而能够“记住”之前序列中的部分信息。这种结构使其适合处理序列数据，如时间序列或自然语言。然而，标准RNN的记忆能力有限，容易受梯度消失问题影响，难以捕捉长距离依赖。
